{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb554a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab05.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ba372-3854-4068-aa5a-19b4a6a2d371",
   "metadata": {},
   "source": [
    "# Lab 5:  Rejection Sampling, Gibbs Sampling and GLM\n",
    "\n",
    "Welcome to the 5th Data 102 lab! \n",
    "\n",
    "The goal of this Lab is to get you familiar with rejection sampling, gibbs sampling, as well as give you additional practice utilizing Bayesian analysis methods with PyMC.\n",
    "\n",
    "## Collaboration Policy\n",
    "You can submit the lab in pairs (groups of two, no more than two). **If you choose to work in a pair, please make sure to add your group member on Gradescope for both Lab 05 written submission and the Lab 05 code submission.**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually and do not share your code with anyone other than your partner**. If you do discuss the assignments with people other than your partner please **include their names** in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961db4c-f97c-4a42-ae87-3d0f072d3772",
   "metadata": {},
   "source": [
    "## Collaborators\n",
    "Write the names of your collaborators in this cell.\n",
    "\n",
    "`<Collaborator Name> <Collaborator e-mail>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a124147-69ae-4685-a520-a1553c6100e0",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Since this lab involves sampling, **tests may take awhile to run. Please submit as early as possible, as last minute submissions may overwhelm DataHub, preventing yourself and others from submitting on-time.**\n",
    "\n",
    "For full credit, this assignment should be completed and submitted before **Wednesday, Feb 26th, 2025 at 5:00 PM PST.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c960e-1f1d-4042-a473-d58c60c82542",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import multivariate_normal, norm, uniform\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import cm\n",
    "\n",
    "import pymc as pm\n",
    "\n",
    "import hashlib\n",
    "\n",
    "sns.set(style=\"dark\")\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "def get_hash(num, significance = 4):\n",
    "    num = round(num, significance)\n",
    "    \"\"\"Helper function for assessing correctness\"\"\"\n",
    "    return hashlib.md5(str(num).encode()).hexdigest()\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import bambi as bmb\n",
    "\n",
    "import arviz as az\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8b75ac-f223-40ac-b01d-bb33b9ddce24",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In this lab, you are given a two dimensional unnormalized density function $q(x,y)$ represented by `target_density` below. The goal of Question 1 of this lab is to build up a sampler that can output samples from the distribution proportional to $q(x,y)$. \n",
    "\n",
    "In **Question 1** we will compute samples via *Rejection Sampling*. In part **1a** we will build a sampler for a 1-dimensional projection of the density. In part **1b** we will extend the approach to two dimensions.\n",
    "\n",
    "*Throughout Question 1, we will assume that our computers have access only to normal and uniform random variables.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a509d4-ccb7-4ae4-b722-64af69764195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the target unnormalized density from which we would like to sample\n",
    "# Run this to define the function\n",
    "# No TODOs here\n",
    "@np.vectorize # <- decorator, makes function run faster\n",
    "def target_density(x, y):\n",
    "    mean1 = [1, 1.7]\n",
    "    mean2 = [2, 1.3]\n",
    "    mean3 = [1.5, 1.5]\n",
    "    mean4 = [2, 2.1]\n",
    "    mean5 = [1, 1.2]\n",
    "    cov1=0.2*np.array([[0.2, -0.05], [-0.05, 0.1]])\n",
    "    cov2 = 0.3*np.array([[0.1, 0.07], [0.07, 0.2]])\n",
    "    cov3= np.array([[0.1, 0], [0, 0.1]])\n",
    "    cov4 = 0.1*np.array([[0.3, 0.04], [0.04, 0.2]])\n",
    "    cov5 = 0.1*np.array([[0.4, -0.04], [-0.04, 0.2]])\n",
    "    return(multivariate_normal.pdf([x, y], mean=mean1, cov=cov1) + \n",
    "           multivariate_normal.pdf([x, y], mean=mean2, cov=cov2) +\n",
    "           2*multivariate_normal.pdf([x, y], mean=mean3, cov=cov3) +\n",
    "           0.5*multivariate_normal.pdf([x, y], mean=mean4, cov=cov4)+\n",
    "           0.5*multivariate_normal.pdf([x, y], mean=mean5, cov=cov5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2802fa-12ad-494e-aee5-a309e7d52a1a",
   "metadata": {},
   "source": [
    "#### Let's visualize this density. \n",
    "\n",
    "Run the cell below to see a 3D plot of the function along with a contour plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834be533-7864-49da-8f73-1e95b5a1449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No TODOs here, just run the cell to make plots\n",
    "# Create a meshgrid of coordinates\n",
    "coords = np.arange(0.5, 2.5, 0.02)\n",
    "X, Y = np.meshgrid(coords, coords)\n",
    "\n",
    "# Compute the value of the target density at all pairs of (x,y) values\n",
    "Z = target_density(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7271054-ad2c-4c1b-b0a6-f9c4e0d34baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 3D plot of the target density\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "\n",
    "ax0 = fig.add_subplot(121, projection='3d')\n",
    "ax1 = fig.add_subplot(122)\n",
    "\n",
    "surf = ax0.plot_surface(X,Y,Z, cmap=cm.plasma, linewidth=0, antialiased=False,alpha = 0.9,)\n",
    "\n",
    "# Customize the z axis.\n",
    "ax0.set_zlim(0, 7)\n",
    "ax0.set_xlabel(\"X\")\n",
    "ax0.set_ylabel(\"Y\")\n",
    "ax0.set_zlabel(\"Z\")\n",
    "ax0.set_title(\"3D plot of the target density\")\n",
    "\n",
    "# Rotate the axes: you can change these numbers in order to see the distribution from other angles\n",
    "ax0.view_init(50, 25)\n",
    "\n",
    "# Plot the contour plot of the density\n",
    "cont = ax1.contour(X,Y,Z, levels = 20, cmap=cm.plasma, linewidths=1)\n",
    "ax1.set_xlabel(\"X\")\n",
    "ax1.set_ylabel(\"Y\")\n",
    "ax1.set_title(\"Contour plot of the target density\")\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5, ax=ax1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd8cab9-a47d-40fa-a58d-673ac440a7f3",
   "metadata": {},
   "source": [
    "Take a moment to examine the plots. Make sure you can see correspondances between each peak in the 3D plot on the left; and the \"high-altitude\" regions in the countour plot on the right.\n",
    "\n",
    "Next we will plot 1-dimensional projections of the target densities onto the $X$ and $Y$ axis. These correspond to conditional target distributions of the form $q(x, y=y')$ and $q(x=x', y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ccd1d-21be-439d-bbde-4d0471a9c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify\n",
    "# Run the cell below to define the plotting functions\n",
    "\n",
    "COORDINATES = np.arange(0, 3, 0.02)\n",
    "def plot_x_cond(y_val):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(12)\n",
    "    axs[0].contour(X,Y,Z, levels = 20, cmap=cm.plasma, alpha = 0.8, linewidths=0.8)\n",
    "    axs[0].axhline(y_val,  ls=\"--\", color = 'olive', lw = 2)\n",
    "    axs[0].set_xlabel(\"X\")\n",
    "    axs[0].set_ylabel(\"Y\")\n",
    "    axs[0].set_title(\"Contour plot of the target density\")\n",
    "    \n",
    "    axs[1].plot(COORDINATES, target_density(COORDINATES, y_val), color = 'olive')\n",
    "    axs[1].set_ylim(0,10)\n",
    "    axs[1].set_xlim(0,3)\n",
    "    axs[1].set_xlabel(\"X\")\n",
    "    axs[1].set_title(\"Conditional target density: q(x | y={:.1f})\".format(y_val))\n",
    "    plt.show()\n",
    "    \n",
    "def plot_y_cond(x_val):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(12)\n",
    "    axs[0].contour(X,Y,Z, levels = 20, cmap=cm.plasma, alpha = 0.8, linewidths=0.8)\n",
    "    axs[0].axvline(x_val,  ls=\"--\", color = 'olive', lw = 2)\n",
    "    axs[0].set_xlabel(\"X\")\n",
    "    axs[0].set_ylabel(\"Y\")\n",
    "    axs[0].set_title(\"Contour plot of the target density\")\n",
    "    \n",
    "    axs[1].plot(COORDINATES, target_density(x_val, COORDINATES), color = 'olive')\n",
    "    axs[1].set_ylim(0,10)\n",
    "    axs[1].set_xlim(0,3)\n",
    "    axs[1].set_xlabel(\"Y\")\n",
    "    axs[1].set_title(\"Conditional target density: q(y | x={:.1f})\".format(x_val))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d685252-c9c2-4ff4-88f3-10072b1d8493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display interactive plot\n",
    "interactive_plot = interactive(plot_x_cond, y_val=(0, 3, 0.1), add_proposal=False)\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409cd282-10bb-4b0f-ba54-9ca57c577deb",
   "metadata": {},
   "source": [
    "Set different values of `y_val`, observe the changes in the conditional target density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477ec47-81e9-403c-a643-ed8af86047c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display interactive plot\n",
    "interactive_plot = interactive(plot_y_cond, x_val=(0, 3, 0.1), add_proposal=False)\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404473c6-fc40-441a-997c-94cf266da5e6",
   "metadata": {},
   "source": [
    "Set different values of `x_val`, observe the changes in the conditional target density."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6e0b6-12dd-4d62-8bcb-8b62e0197c99",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### A Quick Understanding Check:\n",
    "\n",
    "We said that $q$ is an unnormalized density function. What does this mean? How could we test whether or not the function is normalized?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d410076b",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a21c9f5-473b-41e3-bb0a-c8af48bb4547",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Part I: Rejection Sampling and Gibbs Sampling\n",
    "\n",
    "### Question 1: Rejection Sampling\n",
    "\n",
    "In this question, we will build a rejection sampler. First, let's review the basics. \n",
    "\n",
    "Assume we want to sample from an unnormalized target density $q(x)$, using a proposal distribution $F$, with density $f(x)$. The proposal distribution is chosen such that we have access to samples from it. \n",
    "\n",
    "#### Rejection sampling proceeds as follows:\n",
    "\n",
    "- Find constant $c$, such that $cq(x)\\leq f(x)$ on the support\n",
    "- At each iteration:\n",
    "    - Sample $x_i \\sim F$\n",
    "    - Compute the ratio $r = \\frac{c(q(x_i))}{f(x_i)} \\leq 1$\n",
    "    - Sample $\\gamma_i \\sim {\\rm Uniform}(0,1)$:\n",
    "        - `accept` the sample if $\\gamma_i \\leq r$: Add $x_i$ to the list of samples.\n",
    "        - `reject` the sample otherwise: do nothing\n",
    "        \n",
    "### 1(a) Sample from the one-dimensional density $q(x, y=1.2)$\n",
    "Throughout part 1.a, we will restrict our attention to the range $[0,3]$ for simplicity. That way we can use Uniform(0,3) as our proposal distribution. Meaning that $f(x) = \\frac{1}{3} \\ \\forall x\\in[0,3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c403c1-8ecc-477e-bbd2-228ec5b76382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target 1D density q(x, y = 1.2)\n",
    "def target_1D_density(x):\n",
    "    return(target_density(x, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba49e8a-2a82-453d-9008-8424c1440619",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Finish implementing the steps of the rejection sampling algorithm by filling in the following code.\n",
    "\n",
    "*Hint: both `scipy` and `numpy` provide methods for drawing from a uniform distribution.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baf5637-5772-48c5-a94b-95c3e92ba028",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def sample_1D_proposed_distribution(N):\n",
    "    \"\"\" \n",
    "    Produces N samples from the Uniform(0,3) proposal distribution\n",
    "    \n",
    "    Inputs:\n",
    "        N : int, desired number of samples\n",
    "        \n",
    "    Outputs:\n",
    "        proposed_samples : an 1d-array of size N which contains N independent samples from the proposal\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "@np.vectorize\n",
    "def compute_ratio_1D(proposed_sample, c):\n",
    "    \"\"\"\n",
    "    Computes the ratio between the scaled target density and proposal density evaluated at the \n",
    "    proposed sample point\n",
    "    \n",
    "    Inputs:\n",
    "        proposed_sample : float, proposed sample\n",
    "        c : float, constant scaling factor that ensures that the proposal density is above the target density\n",
    "        \n",
    "    Outputs:\n",
    "        ratio : float\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "@np.vectorize\n",
    "def accept_proposal(ratio):\n",
    "    \"\"\" \n",
    "    Accepts or rejects a proposal with probability equal to ratio\n",
    "    \n",
    "    Inputs: \n",
    "        ratio: float, probability of acceptance\n",
    "    \n",
    "    Outputs:\n",
    "        accept: True/False, if True, accept the proposal\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658eeaa3-b701-48a4-ae4a-b5148566c79c",
   "metadata": {},
   "source": [
    "You can use the following cell to test your functions to convince yourself that they work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff43105-34f4-4a9f-9140-f4fe4621dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR TEST CASES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e53ca8-8ab0-4268-9e34-efa24853794b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now we have all the ingredients for making a sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b065d4-7eb4-4370-8d77-0a19728fe431",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def get_1D_samples(N, c): \n",
    "    \"\"\" \n",
    "    Produces samples from target_1D_density\n",
    "    \n",
    "    Inputs:\n",
    "        N : int, number of proposed_samples\n",
    "        c : float, constant scaling factor that ensures that the proposal density is above the target density\n",
    "        \n",
    "    Outputs:\n",
    "        rejection_samples : an 1d-array which contains independent samples from the target\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7619dfb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a_ii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0845d1-d6df-406f-9c5b-fb56e144f5cd",
   "metadata": {},
   "source": [
    "From the interactive plots we made earlier, we can see that $q(x, y=1.2)$ is allways smaller than 5. Hence to make it smaller than $f(x) = 1/3$ we need to scale the target density by a factor $c \\leq \\frac{1}{3}\\cdot\\frac{1}{5} = 1/15$. \n",
    "\n",
    "#### Let's use $c=1/15$, compute target samples and plot their histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf4c99d-ac8b-44b3-8244-a2028a33cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No TODOs here\n",
    "# Just run it once you passed the tests above\n",
    "\n",
    "fig = plt.figure(figsize = (6, 4))\n",
    "c = 1/15\n",
    "target_samples = get_1D_samples(1000, c)\n",
    "density_values =  target_1D_density(COORDINATES)*c\n",
    "plt.plot(COORDINATES, density_values, label='Target')\n",
    "plt.axhline(1/3, ls = '--', label = 'Proposal')\n",
    "n, bins, rects = plt.hist(target_samples, density = True, label=\"Accepted Samples\")\n",
    "max_height = np.max([r.get_height() for r in rects])\n",
    "for r in rects:\n",
    "    r.set_height(r.get_height()*np.max(density_values)/max_height)\n",
    "plt.legend()\n",
    "plt.xlim(0,3)\n",
    "plt.ylim(0,0.45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a661c775-eb02-435b-a075-762bd5bb7392",
   "metadata": {},
   "source": [
    "#### Computing the acceptance ratio for varying scaling constants c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a9a01-5bfc-40d2-aad8-860430148f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No TODOs here\n",
    "# Just run it and comment in the section below\n",
    "\n",
    "N = 1000\n",
    "c_values = [0.06, 0.05, 0.04, 0.03, 0.02, 0.01]\n",
    "for c in c_values:\n",
    "    # compute target samples\n",
    "    target_samples = get_1D_samples(N, c)\n",
    "    acceptance_percentage = 100*len(target_samples)/N\n",
    "    print(\"For c = {:.2f}, the acceptance percentage is {:.1f}%\".format(c, acceptance_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad93215f-3498-4ef8-b2cb-02e488ad1565",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### In the cell below explain why the accepted percentage decreases as $c$ decreases:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b44a1",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5df7e5-c380-43eb-887e-77654b7c19d4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 1(b) Sample from the two-dimensional density $q(x, y)$\n",
    "\n",
    "In two dimensions Rejection Sampling is nearly identical to the 1-dimension case:\n",
    "\n",
    "- Find constant $c$, such that $cq(x, y)\\leq f(x, y)$ on the support\n",
    "- At each iteration:\n",
    "    - Sample $(x_i, y_i) \\sim F$\n",
    "    - Compute the ratio $r = \\frac{c(q(x_i, y_i))}{f(x_i, y_i)} \\leq 1$\n",
    "    - Sample $\\gamma_i \\sim {\\rm Uniform}(0,1)$:\n",
    "        - `accept` the sample if $\\gamma_i \\leq r$: add $(x_i, y_i)$ to the list of samples.\n",
    "        - `reject` the sample otherwise: do nothing\n",
    "\n",
    "Throughout part 1.b we will consider $(x, y)\\sim {\\rm Uniform}(0,3)\\times {\\rm Uniform}(0,3)$ as our proposal distribution. Meaning that $f(x, y) = \\frac{1}{9}\\ \\forall x, y\\in[0,3]$\n",
    "\n",
    "Fill in the 2-d ratio calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a18f23-171d-49b4-b247-7710880524d0",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def compute_ratio_2D(proposed_sample_x, proposed_sample_y, c):\n",
    "    \"\"\"\n",
    "    Computes the ratio between the scaled target density and proposal density evaluated at the \n",
    "    proposed sample point\n",
    "    \n",
    "    Inputs:\n",
    "        proposed_sample_x : float, x components of the proposed sample point\n",
    "        proposed_sample_y : float, y components of the proposed sample point\n",
    "        c : float, constant scaling factor that ensures that the proposal density is above the target density\n",
    "        \n",
    "    Outputs:\n",
    "        ratio : float\n",
    "    \"\"\"\n",
    "    ratio = ...\n",
    "    assert(ratio <= 1)\n",
    "    return(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91d6cd6-03b5-4e38-aa43-1137669fcf32",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Use the following cell to convince yourself that your code is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37f1ab-4b5e-4254-828e-5ed7b589fe45",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR TEST CASES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03cc4ed-6827-47f9-a4dc-7ad4572ad584",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now we have all the ingredients for making the 2-d sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebdf2b-c2c8-4a6d-9070-df92732a89b2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# No TODOs here, just run the 2D version of the functions we built in 1.a\n",
    "def get_2D_samples(N, c): \n",
    "    \"\"\" \n",
    "    Produces samples from target_density\n",
    "    \n",
    "    Inputs:\n",
    "        N : int, number of proposed_samples\n",
    "        c : float, constant scaling factor that ensures that the proposal density is above the target density\n",
    "        \n",
    "    Outputs:\n",
    "        rejection_samples : ndarray of which contains independent samples from the target\n",
    "    \"\"\"\n",
    "    proposed_samples_x = sample_1D_proposed_distribution(N)\n",
    "    proposed_samples_y = sample_1D_proposed_distribution(N)\n",
    "    ratios = compute_ratio_2D(proposed_samples_x, proposed_samples_y, c)\n",
    "    accept_array = accept_proposal(ratios)\n",
    "    proposed_samples = np.concatenate((proposed_samples_x.reshape(N,1), proposed_samples_y.reshape(N,1)), axis = 1)\n",
    "    rejection_samples = proposed_samples[accept_array]\n",
    "    return(rejection_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15529695",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b_i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a212b251-0d07-496d-be56-09e36ef4807b",
   "metadata": {},
   "source": [
    "From the contour plot we made previously, we can see that $q(x, y=1.2)$ is allways smaller than 7.4. Hence to make it smaller than $f(x) = 1/9$ we need to scale the target density by a factor $c \\leq \\frac{1}{7.4}\\cdot\\frac{1}{8} = 0.015$. \n",
    "\n",
    "#### Let's use $c=0.015$, compute target samples and plot them on top the contour lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347aca7d-5174-4121-99dc-651a1b157296",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "\n",
    "# Plot the contour plot of the density\n",
    "cont = plt.contour(X,Y,Z, levels = 20, cmap=cm.plasma, linewidths=1, alpha = 0.8)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Scatterplot of samples obtained via Rejection Sampling\")\n",
    "\n",
    "# Add sample points obtained via rejection sampling\n",
    "c = 1/72\n",
    "target_samples = get_2D_samples(3000, c)\n",
    "plt.scatter(target_samples[:,0], target_samples[:,1], c='b', alpha = 1, s = 10, label = 'Samples')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0aef64-caeb-434e-8183-f396bca57830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to modify this\n",
    "# just run it and comment in the section below\n",
    "\n",
    "N = 3000\n",
    "c_values = [0.015, 0.01, 0.005, 0.001]\n",
    "for c in c_values:\n",
    "    # compute target samples\n",
    "    target_samples = get_2D_samples(N, c)\n",
    "    acceptance_percentage = 100*len(target_samples)/N\n",
    "    print(\"For c = {:.3f}, the acceptance percentage is {:.1f}%\".format(c, acceptance_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0993f1-eb0c-4417-98cd-8c254cae2074",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### In the cell below explain why the accepted percentage when sampling from 2D distribution is so much smaller than sampling from the 1D version in 1(a)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f4ee5",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1eb6a8-f1a6-43eb-98e2-1eb710891060",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 2: Gibbs Sampling\n",
    "\n",
    "In this question, we will build a Gibbs sampler and apply it to the same density. First, let's go over the basics of Gibbs Sampling.\n",
    "\n",
    "Assume we want to sample from an unnormalized target density $q(x, y)$. \n",
    "\n",
    "#### Gibbs Sampling proceeds as follows:\n",
    "\n",
    "- Start at an initial point $(x_0, y_0)$\n",
    "- For `i` in `number of iterations`:\n",
    "    - Condition on $y=y_{i-1}$: Sample $x_i \\sim q(x \\mid y=y_{i-1})$ \n",
    "        - Add $(x_i, y_{i-1})$ to the list of samples\n",
    "    - Condition on $x=x_{i}$: : Sample $y_i \\sim q(y \\mid x=x_{i})$ \n",
    "        - Add $(x_i, y_{i})$ to the list of samples\n",
    "    \n",
    "In many problems we can sample the univariate distributions directly. In this case we don't know how to sample them directly, but we can use the 1-D rejection sampler that we computed in Question 1.\n",
    "\n",
    "In the cell below, we wrote helper functions that sample from the conditionals above. They are essentially the same function you wrote in Question 1, just slightly modified such that we perform rejection sampling until we get one valid sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02402897-10aa-4451-afd0-c617d13de162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No TODOs here:\n",
    "# Just look at these helper functions and make sure you understand the syntax\n",
    "\n",
    "def sample_x_cond(fixed_y_val):\n",
    "    \"\"\" \n",
    "    Produces one sample from x_i ~ q(x | y=fixed_y_val)\n",
    "    \n",
    "    Inputs:\n",
    "        fixed_y_val : float, current value of y, on which we condition\n",
    "    \n",
    "    Outputs:\n",
    "        x_sample: float, one sample from x_i ~ q(x, y=fixed_y_val)\n",
    "        num_samples : int, number of tries until we accepted a sample\n",
    "        \n",
    "    \"\"\"\n",
    "    def conditional_density(x):\n",
    "        return(target_density(x, fixed_y_val))\n",
    "    x_sample = None\n",
    "    num_samples = 0\n",
    "    c = 0.33/(0.2+max(conditional_density(np.arange(0.5, 2.5, 0.05)))) # <- we are cheating a bit here by \n",
    "                                                                       # looking for a tight c value\n",
    "    while x_sample is None:\n",
    "        proposed_sample = sample_1D_proposed_distribution(1)\n",
    "        num_samples += 1\n",
    "        ratio = conditional_density(proposed_sample)*3*c\n",
    "        assert(ratio <= 1)\n",
    "        accept = accept_proposal(ratio)\n",
    "        if accept:\n",
    "            x_sample = proposed_sample[0]\n",
    "    return(x_sample, num_samples)\n",
    "\n",
    "\n",
    "def sample_y_cond(fixed_x_val):\n",
    "    \"\"\" \n",
    "    Produces one sample from y_i ~ q(y | x=fixed_x_val)\n",
    "    \n",
    "    Inputs:\n",
    "        fixed_x_val : float, current value of y, on which we condition\n",
    "    \n",
    "    Outputs:\n",
    "        y_sample: float, one sample from y_i ~ q(y | x=fixed_x_val)\n",
    "        num_samples : int, number of tries until we accepted a sample\n",
    "        \n",
    "    \"\"\"\n",
    "    def conditional_density(y):\n",
    "        return(target_density(fixed_x_val, y))\n",
    "    y_sample = None\n",
    "    num_samples = 0\n",
    "    c = 0.33/(0.2+max(conditional_density(np.arange(0.5, 2.5, 0.05))))\n",
    "    while y_sample is None:\n",
    "        proposed_sample = sample_1D_proposed_distribution(1)\n",
    "        num_samples += 1\n",
    "        ratio = conditional_density(proposed_sample)*3*c\n",
    "        assert(ratio <= 1)\n",
    "        accept = accept_proposal(ratio)\n",
    "        if accept:\n",
    "            y_sample = proposed_sample[0]\n",
    "    return(y_sample, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d16f2ef-4ebb-43d9-bfb6-e49d5443e02d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2(a) Build a Gibbs sampler using the helper functions above\n",
    "**Note**: Don't forget that at each iteration the Gibbs sampler adds two samples to the list of samples: $(x_i, y_{i-1})$ and $(x_i, y_{i})$\n",
    "\n",
    "**Hint 1**: If you cannot pass the test, try making a simple test case with `N=2` and adding some print statements to your code.\n",
    "\n",
    "**Hint 2**: In our implementation of Gibbs sampling, `num_samples` is not trivially equal to `N`, since sampling $x_i \\sim q(x \\mid y=y_{i-1})$ and $y_i \\sim q(y \\mid x=x_{i})$ rely on rejection sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90266a7b-5f6a-40c1-a0de-044d30792cb8",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def get_2D_Gibbs_samples(N, x_0, y_0):\n",
    "    \"\"\"\n",
    "    Produces N samples from the target density using Gibbs Sampling\n",
    "    \n",
    "    Inputs: \n",
    "        N : desired number of samples\n",
    "        x_0, y_0 : floats, the coordinates of the starting point\n",
    "        \n",
    "    Outputs:\n",
    "        gibbs_samples : array of dimension (N, 2) where each row is a sample from the target distribution\n",
    "                        of the form (x_i, y_i)\n",
    "        num_samples : total number of samples required\n",
    "    \"\"\"\n",
    "    gibbs_samples = [] # Each entry corresponds to a (x_i, y_i)\n",
    "    num_samples = 0 # Add the number of samples to this variable, note this is not equal to N since rejection sampling\n",
    "                    # does not accept every sample\n",
    "    x_curr = x_0 # Current value of x, initialized to x_0\n",
    "    y_curr = y_0 # Current value of y, initialized to y_0\n",
    "    \n",
    "    for i in range(N//2): # The range is N//2 since we are generating two gibbs samples in one iteration\n",
    "        ...\n",
    "        \n",
    "    return(gibbs_samples, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d54e70",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea3fb3-83f6-484b-8043-c79f639f9492",
   "metadata": {},
   "source": [
    "### 2(b)  Path traced by the Gibbs sampler\n",
    "Run the code below to overlay the path traced by the Gibbs Sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9699a4-90c1-4cb8-b975-9ec6a797016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not modify\n",
    "# Just run this once you've passed the validation tests above\n",
    "N = 20\n",
    "target_samples, total_samples = get_2D_Gibbs_samples(N, 1, 1)\n",
    "target_samples = np.array(target_samples)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "# Plot the contour plot of the density\n",
    "cont = plt.contour(X,Y,Z, levels = 20, cmap=cm.plasma, linewidths=1, alpha = 0.8)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Path of the Gibbs Sampler\")\n",
    "\n",
    "# Add sample points obtained via Gibbs sampling\n",
    "plt.scatter(target_samples[:,0], target_samples[:,1], c='b', alpha = 1, s=50, label = 'Samples')\n",
    "for i in range(N):\n",
    "    plt.annotate(i, (target_samples[i,0], target_samples[i,1]), fontsize = 20)\n",
    "plt.plot(target_samples[:,0], target_samples[:,1], c='r', alpha = 1, label = 'Path of the Gibbs Sampler')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb334f27-76be-4bf2-9196-1bad0896063f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Inspect the scatter plot above. Trace the Gibbs sampler path from the initial point (labeled 0) to the final point. What do you notice about the orientation of the paths between each point? Why are they oriented in this way?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a98166",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc4d4ee-fb33-4e3a-bafb-72c43875a7ae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 2(c) 'Efficiency' of Gibbs Sampling\n",
    "Let's compute 1000 Gibbs samples and compute how many times the rejection sampling subroutine accepted the proposed sample (running this might take a little while):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab3468-79d3-4172-bebe-a2b6487b6ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to modify this\n",
    "# just run it and comment in the section below\n",
    "N = 1000\n",
    "target_samples, total_samples = get_2D_Gibbs_samples(N, 1, 1)\n",
    "acceptance_rate = N/total_samples*100\n",
    "print(\"The acceptance rate for Gibbs Sampling is {:.1f}%\".format(acceptance_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e559b1c-2db9-4095-83aa-9008794f4e2f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### How does Gibbs Sampling compare to vanilla Rejection Sampling from Question 1? Is this approach more efficient or less efficient? What is the source of this increase/decrease in efficiency?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba583ea2",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee85428-1030-4e84-a39f-dfeead2ecacd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Part II: GLMs\n",
    "\n",
    "Now, we will pivot to discussing frequentist and Bayesian approaches to generalized linear models. This question will be easier after Tuesday's lecture!\n",
    "\n",
    "## Question 3: Atlantic Hurricane Season\n",
    "\n",
    "With 30 named storms, the 2020 Atlantic hurricane season was the most active on record. Climate scientists argue that the culprit is human induced global warming. There is a an evergrowing body of research linking increased average temperatures and rising sea levels to more frequent, more intense and more destructive storms. \n",
    "\n",
    "In this lab we will investigate the number of named storms recorded since 1880, and we will argue that there is a statistically significant relationship between rising Sea Surface Temperature (SST) and the frequency of named storms.\n",
    "\n",
    "For this lab we extracted the number of tropical storms from the [HURDAT Database](https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2019-052520.txt). We also extracted data on Sea Surface Temperatures from the [National Center for Atmosferic Research](https://climatedataguide.ucar.edu/climate-data/global-surface-temperature-data-gistemp-nasa-goddard-institute-space-studies-giss). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf35095-1c79-48d3-9544-81e22560704a",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb161f0-f5ca-4037-aa0b-83f5ae04a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to modify: Just run the code to load the data\n",
    "data_source = \"hurricane_data.csv\"\n",
    "df = pd.read_csv(data_source)\n",
    "df = df[[\"Year\", \"Num_Storms\", \"Temp_Anomaly\"]]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b5753-8dcc-4a9c-b56a-4ad54751fdff",
   "metadata": {},
   "source": [
    "### Model Specifications\n",
    "\n",
    "The `Num_Storms` column contains the number of named storms recorded each year between 1880 and 2019. The `Temp_Anomaly` column contains the deviation in yearly SST from the mean of 1951-1980.\n",
    "\n",
    "In this question, to show that there is a statistically significant relationship between rising Sea Surface Temperature (SST) and the frequency of named storms, we will model the number of named storms in Year $i$ using **Poisson Regression**:\n",
    "\n",
    "$$\\lambda_i = e^{q_0 + q_1 X_i}$$ \n",
    "\n",
    "$$C_i \\sim \\text{Poisson}(\\lambda_i),$$\n",
    "\n",
    "where $X_i$ is the SST deviation in Year $i$, and $C_i$ is the number of named storms in year $i$.\n",
    "\n",
    "This isn't something that we can easily solve from scratch, so we have to use software packages. In this question, we'll explore the two approaches to GLMs that we covered in class: \n",
    "\n",
    "1. **Q3(b): Frequentist Regression** using [`statsmodels.api`](https://www.statsmodels.org/stable/glm.html) \n",
    "2. **Q3(c) Bayesian Regression** via sampling using [`PyMC`](https://www.pymc.io/welcome.html) and [`Bambi`](https://bambinos.github.io/bambi/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e23feb7-0bbd-4866-aec8-0a849a3d5129",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3(a) Understanding Check\n",
    "\n",
    "The model we described above is a GLM. What is \"Linear\" about this GLM model? What's the inverse link function? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42676a9",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a4fac2-3302-4a71-ad7d-3f2fb918b69f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 3(b) Frequentist Regression\n",
    "\n",
    "Let's start by considering the problem from a frequentist lens. To do this, we'll use the `statsmodels.api`, which allows us to create a model in just a few lines of code.\n",
    "\n",
    "After fitting our model, we can call the `.summary()` method, and get a breakdown of our model and some details on how well it fit our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6943a-77eb-4fc0-a441-5e3e5b265b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Poisson GLM model where Temp_Anomaly is a covariate (exogenous variable): No need to modify\n",
    "freq_model = sm.GLM(df[\"Num_Storms\"], exog = sm.add_constant(df[\"Temp_Anomaly\"]), \n",
    "                  family=sm.families.Poisson())\n",
    "freq_res = freq_model.fit()\n",
    "print(freq_res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca01aa6-824e-4115-a362-a9a92974c14d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3(b)(i) Understanding the table\n",
    "\n",
    "What variable does `Temp_Anomaly`'s `coef` in the table correspond to in our model? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2efcdae",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400db3cc-1471-4cbe-95d1-755ab7ae00bc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3(b)(ii) Inspecting the results of fitting `freq_model`. \n",
    "\n",
    "Does the model suggest that increased SST relate to more storms? Is the influnce of SST on number of storms statistically significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8820e0df",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0bb97-d958-4fde-9cad-a4ad7c055d71",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 3(c) Bayesian Regression via PyMC\n",
    "\n",
    "Now that we've done Poisson regression the frequentist way with the `statsmodels` package, let's try implementing it the Bayesian way! In this lab we'll explore two ways of doing this:\n",
    "1. Building the model from scratch in `PyMC`\n",
    "2. Using `Bambi`, a wrapper on `PyMC` that simplifies model construction\n",
    "\n",
    "To start, let's build our model from scratch in `PyMC`. Unlike the `statsmodels` package, `PyMC` requires us to specify our model piece by piece. That means that, as with any Bayesian parameter estimation task, we have to distill our problem setup into a likelihood and prior before we can proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968bca8-a00e-4b9f-8681-58a2e1bacb62",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 3(c)(i) Unpacking $C_i \\sim \\text{Poisson}(\\lambda_i)$\n",
    "\n",
    "Recall the problem setup:\n",
    "\n",
    "Our model involves the relationship between rising Sea Surface Temperature (SST) and the frequency of named storms, where:\n",
    "\n",
    "$$\\lambda_i = e^{q_0 + q_1 X_i}$$ \n",
    "\n",
    "$$C_i \\sim \\text{Poisson}(\\lambda_i),$$\n",
    "\n",
    "where $X_i$ is the SST deviation in Year $i$, and $C_i$ is the number of named storms in year $i$.\n",
    "\n",
    "**In the cell below, Choose the option that best fills in the blank in the following statement:**\n",
    "\n",
    "$C_i \\sim \\text{Poisson}(\\lambda_i)$ represents our _____:\n",
    "\n",
    "**A.** Prior\n",
    "\n",
    "**B.** Likelihood\n",
    "\n",
    "**C.** Posterior\n",
    "\n",
    "Your answer should be a string, either `\"A\"`, `\"B\"`, or `\"C\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76faca57-70c2-41a8-9a22-6fdd194428cc",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "q3c_i = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611b8687",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c_i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f468b6-ca5e-4f09-a323-2852f29dae66",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3(c)(ii) Picking our prior(s)\n",
    "\n",
    "Now, let's examine the parameter $\\lambda_i = e^{q_0 + q_1 X_i}$. As discussed in lecture, $\\lambda_i$ is comprised of a linear function of our observations ($q^TX$) and an inverse-link function ($e$). Given the setup of our problem, answer the following questions using 1 sentence each:\n",
    "1. How many prior distributions do we need to define?\n",
    "2. What parameters will we define these prior distributions for?\n",
    "3. Since we don't have any prior information about these random variables, what distribution (i.e Normal, Beta, etc.) should we pick for their priors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f1954",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2adcda0-c9e2-4075-8d56-69a2f79a07ae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 3(c)(iii) Defining our PyMC Model\n",
    "Given your answers to `q2c_i` and `q2c_ii`, you're now ready to make your PyMC model! Fill out the code cell below to build your model and sample from the posterior.\n",
    "\n",
    "**Note:** To pass the test, \n",
    "1. Do not remove the variables currently present in the model and/or add your own additional variables. Just fill in any ellipsis; the variables defined here are more than enough for you to solve the question!\n",
    "2. Make sure the name parameter you pass to each `Distribution` object matches the variable name it's assigned to. Your answers should follow the following format: \n",
    "\n",
    "```\n",
    "with pm.Model() as model:\n",
    "\n",
    "    q0 = pm.Some_Distribution('q0', ...)\n",
    "    q1 = pm.Some_Distribution('q1', ...)`\n",
    "    ...\n",
    "```\n",
    "\n",
    "**Hint 1**: Remember that random variables can be added, subtracted, multiplied, etc. just like normal numbers!\n",
    "\n",
    "**Hint 2**: Not all variables defined in a model context necessarily have to be defined using `pm.Some_Distribution(...)`. In particular, we do not need `pm.Deterministic` when defining `lam`, since we're not interested in its posterior samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904ef19-fc93-49a4-bcc0-d001d73b53cb",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    q0 = ...\n",
    "    q1 = ...\n",
    "\n",
    "    lam = ...\n",
    "    \n",
    "    Y_obs = ...\n",
    "\n",
    "    # DO NOT CHANGE THE SAMPLING ROUTINE\n",
    "    trace = pm.sample(2000, chains = 4, random_seed = 0, return_inferencedata = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb0daf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c_iii\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e19102-25bc-4072-8f51-1c723b9d2966",
   "metadata": {},
   "source": [
    "Now that we've ran PyMC, we can visualize the posterior distributions of $q_0$ and $q_1$ and find our estimates $\\hat{q}_0$ and $\\hat{q}_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a7786-e38e-4d38-add6-6d9d4b296f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace, round_to=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347215cc-0eb1-44db-a5b6-c0f0c56b5926",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 3(d) Bayesian Regression via Bambi\n",
    "\n",
    "Whew! `q3(c)` took *a lot* of code just to build a simple Poisson regression. In practice, building models from scratch like this is usually unnecessary unless we're looking for a custom solution. Instead, we can rely on packages like `Bambi` that *wrap* the functionality of `PyMC` with a simpler interface purely designed for GLMs.\n",
    "\n",
    "Using [`Bambi` documentation](https://bambinos.github.io/bambi/) as a guide, fill out the code cell below to fit a Bayesian Poisson Regression model on our data. \n",
    "\n",
    "**Note 1**: To pass the autograder, make sure you pass your model the `random_seed = 0` when you fit it!\n",
    "\n",
    "**Note 2**: Notice that the `Bambi` package doesn't need us to specify a prior: when we don't specify a prior for our model parameters, Bambi automatically supplies a weakly informative one based on your data by default. For this question, we are okay with this behavior: **to pass the test, do not specify a prior on your parameters!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f30b5c9-ad61-46de-b865-115b3c2d0568",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "my_model = ...\n",
    "my_model_samples = ...\n",
    "\n",
    "az.plot_posterior(my_model_samples, round_to=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843e707",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ab5b5e-2704-4ae0-87e7-1e4b94b80f6e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3(e) Understanding the plots\n",
    "What the are x-axis and y-axis in each of the plots in 3d)? Your answer should be in terms of the parameters of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61963bea",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f030ff-91cf-4393-b6d1-d126e65ec33c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 3(f) Comparison\n",
    "\n",
    "Compare the results of `freq_model` in 3(b) with the plot in 3(d). Are the estimates of Frequentist and Bayesian Regression close to each other? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711d6ab2",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c730d0-867c-4f3d-936d-08daaf43f333",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Well done!\n",
    "You've reached the end of the lab! Make sure you double check your work and make sure that you've answered all the written portions of the lab.\n",
    "\n",
    "Before you submit to Gradescope, make sure you pass all the autograded portions of this lab. **Run the cell below to generate a PDF of your lab submission**, and **run the last cell to generate a zip file of your lab submission.** Do **not** create your lab PDF by exporting your notebook to a PDF.\n",
    "\n",
    "To submit your lab to Gradescope, submit the PDF to Lab 5 Written and the zip file to Lab 5 Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4d236-fe48-4d1f-a59a-ae8fb0b50838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from otter.export import export_notebook\n",
    "from os import path\n",
    "from IPython.display import display, HTML\n",
    "export_notebook(\"lab05.ipynb\", filtering=True, pagebreaks=True)\n",
    "if(path.exists('lab05.pdf')):\n",
    "    img = mpimg.imread('baby_seal.png')\n",
    "    imgplot = plt.imshow(img)\n",
    "    imgplot.axes.get_xaxis().set_visible(False)\n",
    "    imgplot.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    display(HTML(\"Download your PDF <a href='lab05.pdf' download>here</a>.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27741701",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bcfbe5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac2b149",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d832e8c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57059b",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a_ii": {
     "name": "q1a_ii",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> N = 1000\n>>> tests = [np.abs(1.5 - np.mean(get_1D_samples(N, 1 / 15))) < 0.1, np.abs(0.3 - len(get_1D_samples(N, 1 / 15)) / N) < 0.05, np.abs(0.23 - len(get_1D_samples(N, 1 / 20)) / N) < 0.05, np.abs(0.18 - len(get_1D_samples(N, 1 / 25)) / N) < 0.05]\n>>> assert np.all(tests)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b_i": {
     "name": "q1b_i",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> N = 5000\n>>> tests = [np.abs(0.075 - len(get_2D_samples(N, 0.015)) / N) < 0.015, np.abs(0.045 - len(get_2D_samples(N, 0.01)) / N) < 0.015]\n>>> assert np.all(tests)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> N = 100\n>>> output = get_2D_Gibbs_samples(N, 1, 1)\n>>> assert len(output) == 2\n>>> assert len(output[0]) == 100\n>>> assert len(output[0][0]) == 2\n>>> assert np.abs(410 - output[1]) < 100\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c_i": {
     "name": "q3c_i",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert q3c_i.upper() == 'B'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c_iii": {
     "name": "q3c_iii",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> first_q0_10 = np.array([2.31040879, 2.28676486, 2.21883405, 2.21736877, 2.22888946, 2.21329085, 2.23160438, 2.24657932, 2.27997392, 2.26348672])\n>>> assert np.allclose(trace.posterior.q0[:, :].to_numpy().flatten()[:10], first_q0_10)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> first_q1_10 = np.array([0.48528855, 0.45162568, 0.58493267, 0.56287812, 0.59027936, 0.54309099, 0.42550684, 0.4674696, 0.46644434, 0.55409565])\n>>> assert np.allclose(trace.posterior.q1[:, :].to_numpy().flatten()[:10], first_q1_10)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3d": {
     "name": "q3d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bambi_ta_10 = np.array([0.4844136, 0.4844136, 0.52475228, 0.5088275, 0.5088275, 0.37721286, 0.44015103, 0.50478428, 0.40513035, 0.43697324])\n>>> assert np.allclose(my_model_samples.posterior.Temp_Anomaly.to_numpy().flatten()[:10], bambi_ta_10)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bambi_int_10 = np.array([2.20638771, 2.20638771, 2.26402576, 2.2418237, 2.2418237, 2.21996355, 2.26259078, 2.22356198, 2.23562492, 2.27393475])\n>>> assert np.allclose(my_model_samples.posterior.Intercept.to_numpy().flatten()[:10], bambi_int_10)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
