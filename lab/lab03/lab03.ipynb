{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cf085",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab03.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae375b5-4021-44a7-b356-b57078202a91",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 3:  Loss and Risk\n",
    "Welcome to the third Data 102 lab! \n",
    "\n",
    "The goal of this lab is to introduce loss functions in hypothesis testing problems.\n",
    "\n",
    "The code and responses you need to fill in are represented by `...`. There is additional documentation for each part as you go along. \n",
    "\n",
    "## Collaboration Policy\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually and do not share your code with anyone other than your partner**. If you do discuss the assignments with people other than your partner please **include their names** in the cell below.\n",
    "\n",
    "You can submit the lab in pairs (groups of two, no more than two). **If you choose to work in a pair, please make sure to add your group member on Gradescope for both Lab 03 written submission and the Lab 03 code submission.**\n",
    "\n",
    "## Submission\n",
    "\n",
    "**For full credit, this assignment should be completed and submitted before Wednesday, February 12th, 2023 at 5:00 PM PT.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82850cc-7153-4424-a3d0-f2bf59703258",
   "metadata": {},
   "source": [
    "## Collaborators\n",
    "Write the names of your collaborators in this cell.\n",
    "\n",
    "`<Collaborator Name> <Collaborator e-mail>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346723d-3fb0-41a7-89a9-9c403541e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import itertools\n",
    "from ipywidgets import interact, interactive\n",
    "\n",
    "import hashlib\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style=\"dark\")\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4260a01c-b54d-4018-be5b-0f1db35474d5",
   "metadata": {},
   "source": [
    "## Question 1: Custom Loss Functions for Hypothesis Testing\n",
    "\n",
    "The first question looks at a medical diagnostic decision. For each person that undergoes testing, the null hypothesis is that they don't have the virus, and the alternative is that they do.\n",
    "\n",
    "_The null hypothesis_ $H_0$: Person $X$ does not have the virus.\n",
    "\n",
    "_The alternative hypothesis_ $H_1$: Person $X$ has the virus.\n",
    "\n",
    "Suppose that you devise a test which takes some measurements from each test subject and then computes a corresponding p-value.\n",
    "\n",
    "Last week, we looked at several approaches for controllling False Positive Rate (FPR), Family Wise Error Rate (FWER) and False Discovery Rate (FDR). However, they all have some drawbacks for medical decision making: FPR and FWER do not depend on the prevalence of the disease and neither of them allows a decision maker to consider different misclassification costs arising from false-negative and false-positive diagnoses.\n",
    "\n",
    "When making medical decisions, wrong diagnoses carry different costs. Deciding that a patient does not have the virus when in reality they do is a **False Negative**. The potential consequences of such a decision are severe: lack of treatment, risk of infecting others, and even premature death.\n",
    "\n",
    "On the other hand, deciding that a patient has the virus when in reality they don't is a **False Positive**. The potential consequences of that include distress, unnecesary treatment and costs of subsequent testing. This is certainly not ideal, but less severe than the consequences of a false negative.\n",
    "\n",
    "We've previously evaluated decisions in terms of their TPR and FPR, and showed how ROC curves demonstrate the trade-off curve between the two quantities. We saw that it is not always clear how to choose the best trade-off.\n",
    "\n",
    "A very popular way of choosing the trade-off, and simultaneously comparing different procedures, is the idea of **risk** that we learnt in Lecture 5. Here, the analyst constructs a loss function by specifying the **cost** of making each type of mistake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87961fa-4c0e-46bd-836e-9ceebe5ead92",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 1a. Defining a loss function\n",
    "\n",
    "Let's assume that we estimate the cost of making a false negative mistake to be $k$-times larger than the cost of a false positive. We can express that via a **loss function**, shown below:\n",
    "\n",
    "$$\\begin{cases} \\mathcal{l}(D=1 \\mid R=0) = 1\\\\\n",
    "\\mathcal{l}(D=0\\mid R=1) = ~?\\\\\n",
    "\\mathcal{l}(D=0\\mid R=0)=\\mathcal{l}(D=1|R=1) = 0\\end{cases}$$\n",
    "\n",
    "What should be the value of $~?$ in the equation above? Assign your answer to the variable `question_mark` below **as a string**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb0ae23-89fe-45af-b198-8bb604640b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_mark = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b784b77",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a_i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00abf38-ddc5-4723-b027-1a784fe37884",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Do FPR and FWER depend on the prevalence of the disease?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4dc20d",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc69a7d-1bb6-4c46-a75f-c8d94bbd6f0b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Above, you were given one example of when the consequences of a False Negative is more severe than the consequences of a False Positive. Come up with one example of the opposite: when the consequences of a False Positive is more severe than the consequences of a False Negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e69e7a",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfdebe-a22d-41f8-81cc-012178e33339",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 1b. Compute average empirical loss\n",
    "\n",
    "Assume we have a sample of $N$ patients for which a test outputs the following confusion matrix: \n",
    "\n",
    "|             | Decision = 0 | Decision = 1 |\n",
    "|-------------|--------------|--------------|\n",
    "| Reality = 0 | TN           | FP           |\n",
    "| Reality = 1 | FN           | TP           |\n",
    "\n",
    "Compute the average loss this procedure incurs by summing up the losses for every mis-diagnosis and then dividing by the total number of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ca5ff6-3f3e-41ce-8af8-5a0ff61309f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_average_loss(results_dictionary, factor_k):\n",
    "    \"\"\" Function that computes average loss for a given confusion matrix and a multiplicative\n",
    "        factor_k that compares the consequences of false nagatives and false positives.\n",
    "        \n",
    "        Inputs:\n",
    "            results_dictionary : a dictionary with the counts of TP, FP, TN and FN\n",
    "            factor_k : float, quantifies the ratio of the negative consequences of\n",
    "                       false negatives compared to false positives\n",
    "                       \n",
    "        Outputs:\n",
    "            average_loss : float\n",
    "    \"\"\"\n",
    "    \n",
    "    TP_count = results_dictionary['TP_count']\n",
    "    FP_count = results_dictionary['FP_count']\n",
    "    TN_count = results_dictionary['TN_count']\n",
    "    FN_count = results_dictionary['FN_count']\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9847454",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414ac60-8c85-4aca-97ab-437402e2560b",
   "metadata": {},
   "source": [
    "### 1c. Compute the average loss (empirical risk) with respect to various levels $\\alpha$\n",
    "\n",
    "In this part, we will use a simple test that rejects the null hypothesis whenever the p-value of a patient is smaller than some level $\\alpha$. \n",
    "\n",
    "Our goal is to investigate the performance of the test at different levels with respect to the custom loss defined in **1.b**. \n",
    "\n",
    "Recall the naive test from Lab 01:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fbe542-b515-4a2c-8ec7-532e7665527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_threshold_decisions(p_values, alpha):\n",
    "    \"\"\"\n",
    "    Returns decisions on p-values using naive thresholding.\n",
    "    \n",
    "    Inputs:\n",
    "        p_values: array of p-values\n",
    "        alpha: threshold (significance level)\n",
    "    \n",
    "    Returns:\n",
    "        decisions: binary array of same length as p-values, where `decisions[i]` is 1\n",
    "        if `p_values[i]` is deemed significant at level `alpha`, and 0 otherwize\n",
    "    \"\"\"\n",
    "    decisions = p_values <= alpha\n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ebe090-7a30-4389-8bd0-c10f76bb2aa7",
   "metadata": {},
   "source": [
    "Let's also bring in from Lab 01 the function that computes the counts of TP, TN, FP, FN by comparing the decision to the reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec3870-a330-4ea4-b9d3-b72fadf02848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(decisions, reality):\n",
    "    \"\"\"\n",
    "    Produces a dictionary with counts for the true positives, true negatives,\n",
    "    false negatives, and false positives from the input `decisions`\n",
    "    and `reality` arrays.\n",
    "    \n",
    "    Inputs:\n",
    "      decision: array of 0/1 values where 1 indicates that patient has the virus.\n",
    "      reality: array of 0/1 values where 1 indicates a draw from the alternative.\n",
    "    \n",
    "    Outputs: a dictionary of TN, TP, FN, and FP counts.\n",
    "    \"\"\"   \n",
    "    \n",
    "    TP_count = np.sum(decisions*reality)\n",
    "    TN_count = np.sum((1-decisions)*(1-reality))\n",
    "    FP_count = np.sum((decisions)*(1-reality))\n",
    "    FN_count = np.sum((1-decisions)*(reality))\n",
    "    \n",
    "    results_dictionary = {\"TN_count\": TN_count,\n",
    "                          \"TP_count\": TP_count,\n",
    "                          \"FN_count\": FN_count,\n",
    "                          \"FP_count\": FP_count,\n",
    "                         }\n",
    "    return results_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25beefb1-63ca-4087-9c83-2ca123f277ee",
   "metadata": {},
   "source": [
    "First, we will generate ground truth data. \n",
    "\n",
    "Assume there are $N$ subjects, out of which a fraction truly have the virus. This fraction is known as **prevalence**: $\\mathbb{P}\\{R=1\\}$.\n",
    "\n",
    "The function below generates p-values associated with each test subject. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea444bf-5826-4650-a75b-c9f5e86b9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ground_truth(N, prevalence):\n",
    "    \"\"\" Creates simulated p-values corresponding to N subjects at a \n",
    "    specified disease prevalence level\"\"\"\n",
    "    rs = np.random.RandomState(1)\n",
    "    reality = rs.binomial(1, prevalence, N)\n",
    "    p_values = 1 - norm.cdf(rs.randn(N) + reality)\n",
    "    return(p_values, reality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ee8c1-160c-4c2d-a4a3-47fa8a546bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "prevalence = 0.1\n",
    "p_values, reality = generate_ground_truth(N, prevalence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a2b52a-8b9d-48f8-bf55-fb37fe3907d2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the cell below, complete the function that computes the average loss (empirical risk) for an $\\alpha$ level test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22452d6-024f-4141-94b7-4573abc7194d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: complete the function\n",
    "def compute_alpha_average_loss(p_values, reality, alpha, factor_k):\n",
    "    \"\"\" \n",
    "    Computes the observed average loss for an alpha level test.\n",
    "    \n",
    "    Inputs:\n",
    "        p_values: array of floats, p-value[i] is the p-values associated with test subject i.\n",
    "        reality: array of 0/1s\n",
    "        alpha: float, threshold for rejecting the null hypothesis\n",
    "        factor_k: float, quantifies the ratio of the negative consequences of\n",
    "                  false negatives compared to false positives\n",
    "                  \n",
    "    Outputs:\n",
    "        average_loss: float, average observed loss\n",
    "    \"\"\"\n",
    "    \n",
    "    # HINT: Your code should take advantage of functions already defined in this notebook.\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f458b1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4212081-3010-4c3f-820e-8f88a4b6a375",
   "metadata": {},
   "source": [
    "### 1d. Investigate the average loss plot for different levels of disease prevalence \n",
    "The function below generates ground truth for a sample of 10000 subjects for a given disease prevalence. It then computes the average loss for diagnostic decisions at level $\\alpha$, where $\\alpha \\in [0, 1]$ . Finally, it plots the resulting average loss (y axis) at a level $\\alpha$ (x axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f5392-4a25-479f-941e-c1d4c00c353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this as is after completing the `compute_alpha_average_loss` function\n",
    "# Do not modify\n",
    "def plot_average_loss(prevalence, factor_k):\n",
    "    N = 10000\n",
    "    # generate ground truth\n",
    "    p_values, reality = generate_ground_truth(N, prevalence)\n",
    "    # vary alpha from 0 to 1\n",
    "    alpha_array = np.arange(0,1, 0.05)\n",
    "    # compute average loss for each alpha\n",
    "    average_loss_array = [compute_alpha_average_loss(p_values, reality, alpha, factor_k) for alpha in alpha_array]\n",
    "    optimal_alpha = alpha_array[np.argmin(average_loss_array)]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(alpha_array, average_loss_array, label = 'Average Loss')\n",
    "    plt.axvline(x=optimal_alpha, ls='--', label = 'Optimal $\\\\alpha$', c='green')\n",
    "    plt.xlabel('$\\\\alpha$ level')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb415a9-d43e-43cc-a886-cb0fd35afce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize interactive plot: Do not modify\n",
    "interactive_plot = interactive(plot_average_loss, prevalence=(0.0, 0.11, 0.01), factor_k=(0, 100, 5))\n",
    "interactive_plot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d862c-1d34-4b64-b974-eada02c5cc58",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Fix the `prevalence` of the disease at $0.05$ ($5\\%$). Using the slider in the interactive plot above, try out different values for the multiplicative `factor_k`. What do you notice? How would you adjust your diagnosic procedure based on the value of `factor_k`? What combination of `factor_k` and $\\alpha$ gives you the lowest possible loss, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb29b4b",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d5691-c464-4eb6-b936-3cef3bcc5f24",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Fix `factor_k` at $50$ (meaning that the negative consequence of a false negative are 50 times larger than the negative consequences of a false positive). Using the slider in the interactive plot above, try out different values for the true prevalence of the disease. What do you notice? How would you adjust your diagnostic procedure based on the prevalence of the disease? What combination of prevalence and $\\alpha$ gives you the lowest possible loss, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494fdb71",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5522c072-7b7c-4234-9b9a-edf57f02fe52",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Question 2: Making Decisions\n",
    "In the previous question you played the role of a test designer or device manufacturer that needs to find an appropriate way to calibrate the test such that it minimizes some desired loss. In this part put yourself in the shoes of a medical professional who is using this testing device without really knowing all the internals of it. \n",
    "\n",
    "The test kit claims a certain specificity (${\\rm TNR} = 1 - {\\rm FPR}$) and sensitivity (${\\rm TPR} = 1 - {\\rm FNR}$). \n",
    "\n",
    "Assume you have a new patient that came in and tested positive (you have only the binary output of the test). Your goal is to determine whether or not to put this patient through treatment.\n",
    "\n",
    "To answer this we will make the following assumptions:\n",
    "- Assume as in part 1, that getting a false negative is $k$ times worse than getting a false positive.\n",
    "- Assume that you know the `prevalence` of this disease.\n",
    "- Assume that the test has a certain `specificity` and `sensitivity`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97fd509-2230-4358-bd83-3e19229cfd2a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2a. Compute the posterior\n",
    "Complete the function below to compute the posterior probability that the patient truly has the disease conditioned on a positive test result: namely, compute $\\mathbb{P}\\{R=1 \\mid D=1\\}$ as a function of `prevalence`, `sensitivity` and `specificity`.\n",
    "\n",
    "*Hint: We've already seen this in HW1 and Discussion 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d61e5-199d-4d27-9d0b-a7bc8b371375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_posterior_probability(prevalence, sensitivity, specificity):\n",
    "    \"\"\" \n",
    "    Computes the posterior probability that the patient trully has the disease \n",
    "    conditioned on a positive test result.\n",
    "    \n",
    "    Inputs: \n",
    "        prevalence: float, fraction of the population that has the disease\n",
    "        sensitivity: float, 1 - false negative rate\n",
    "        specificity: float, 1 - false positive rate\n",
    "        \n",
    "    Outputs:\n",
    "        posterior probability: probability that the patient has the disease given a positive test result\n",
    "    \"\"\"\n",
    "    ...\n",
    "    posterior_probability = ...\n",
    "    return round(posterior_probability, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6315f2f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffc135-8a7f-45e2-8b4d-7bb761b7c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute a few posterior probabilities\n",
    "prevalence = [0.001, 0.1]\n",
    "sensitivity = 0.98\n",
    "specificity = 0.99\n",
    "print('Conditioned on a positive test result, with sensitivity {} and specificity {}:'.format(sensitivity, specificity))\n",
    "print('For a low prevalence disesase ({}), the posterior probability that the test subject is truly positive is {:.3f}'.\n",
    "      format(prevalence[0], compute_posterior_probability(prevalence[0], sensitivity, specificity)))\n",
    "print('For a high prevalence disesase ({}), the posterior probability that the test subject is truly positive is {:.3f}'.\n",
    "      format(prevalence[1], compute_posterior_probability(prevalence[1], sensitivity, specificity)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c4977-e7bb-4fca-b4e1-dda1b82a2331",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### 2b. Compute expected loss function with respect to posterior distribution\n",
    "\n",
    "Given that the test returned a positive result (that $D=1$), you can make one of two posible decisions:\n",
    " - $T = 1$: start the treatment\n",
    " - $T = 0$: do not start the treatment despite the positive test result\n",
    " \n",
    "Similarly to Question 1, let's assume that we estimate the cost of not treating a truly sick patient to be $k$ times larger than the cost of treating a patient that is not truly sick.\n",
    "\n",
    "Recall from lecture that a loss function takes in a hidden state of the world $\\theta$ (in this case, that's the reality $R$: whether or not the patient is sick), and a decision $\\delta$ (in this case, that's $T$: whether or not to treat). Our loss function has the formula:\n",
    "\n",
    "$$\\begin{cases} \\ell(R=0, T=1) = 1\\\\\n",
    "\\ell(R=1, T=0) = k\\\\\n",
    "\\ell(R=0, T=0)=\\ell(R=1, T=1) = 0\\end{cases}$$\n",
    "\n",
    "Compute the expected loss for each treatment decision, given that someone tested positive:\n",
    "$$\\mathbb{E}[\\ell(R,T=0)|D=1] = ?$$\n",
    "$$\\mathbb{E}[\\ell(R,T=1)|D=1] = ?$$\n",
    "\n",
    "*Hint: Think carefully about what is random here. What's it's distribution?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc8e11-fedd-44bc-b434-74193e1f1c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_expected_loss(treatment, posterior_probability, factor_k):\n",
    "    \"\"\" \n",
    "    Compute the expected loss for the treatment.\n",
    "    \n",
    "    Inputs:\n",
    "        treatment: int 0/1 (0-no treatment, 1-treatment)\n",
    "        posterior_probability: float, probability that the patient is truly sick given positive test result\n",
    "        factor_k : float, quantifies the ratio of the negative consequences of\n",
    "                   false negatives compared to false positives\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b6442",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07d9d7-00d2-47d6-8e4f-9089bae1bb3c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2c. Loss and Risk\n",
    "Is the quantity you computed above a frequentist risk, a Bayesian posterior risk, or neither? Explain why in two sentences or less."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a3e7a2",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339df397-b01a-4b71-b5ac-799d42f9e9b8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 2d. Decide whether or not to administer the treatment by comparing the expected losses in each case.\n",
    "\n",
    "Compare the cost for `treatment T=1` and `no treatment T=0` and choose the option with lower expected loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd9856-64b1-4c7b-b244-b2dac68d37b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: complete the function\n",
    "def make_decision(posterior_probability, factor_k):\n",
    "    \"\"\"\n",
    "    Make a decisions to adminster or not the treatment: T=1 or T=0 .\n",
    "    \n",
    "    Inputs: \n",
    "        posterior_probability: float, probability that the patient is truly sick given positive test result\n",
    "        factor_k : float, quantifies the ratio of the negative consequences of\n",
    "                   false negatives compared to false positives\n",
    "    Outputs:\n",
    "        treatment: int, 0/1\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f36a8b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac84ee1-7a12-4fd0-a58f-f7c605140316",
   "metadata": {},
   "source": [
    "## Well done!\n",
    "You've reached the end of the lab! Make sure you double check your work and make sure that you've answered all the written portions of the lab (1a has two written questions, 1d has two written questions, and 2c has one).\n",
    "\n",
    "Before you submit to Gradescope, make sure you pass all the autograded portions of this lab. **Run the cell below to generate a PDF of your lab submission**, and **run the last cell to generate a zip file of your lab submission.** Do **not** create your lab PDF by exporting your notebook to a PDF.\n",
    "\n",
    "To submit your lab to Gradescope, submit the PDF to Lab 3 Written and the zip file to Lab 3 Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6b0b00-44d9-4994-88f0-09f1125030a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from otter.export import export_notebook\n",
    "from os import path\n",
    "from IPython.display import display, HTML\n",
    "export_notebook(\"lab03.ipynb\", filtering=True, pagebreaks=True)\n",
    "if(path.exists('lab03.pdf')):\n",
    "    img = mpimg.imread('baby_donkey.jpg')\n",
    "    imgplot = plt.imshow(img)\n",
    "    imgplot.axes.get_xaxis().set_visible(False)\n",
    "    imgplot.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    display(HTML(\"Download your PDF <a href='lab03.pdf' download>here</a>.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2c8a4f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8902a1a3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336cf424",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda2c2c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44872620",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a_i": {
     "name": "q1a_i",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert question_mark == 'k'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> res_dict = {'TP_count': 100, 'FP_count': 20, 'TN_count': 450, 'FN_count': 30}\n>>> k_factors = [0, 10, 100]\n>>> avg_losses = [compute_average_loss(res_dict, k) for k in k_factors]\n>>> assert np.isclose(compute_average_loss(res_dict, 0), 0.03333333333333333)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> res_dict = {'TP_count': 100, 'FP_count': 20, 'TN_count': 450, 'FN_count': 30}\n>>> k_factors = [0, 10, 100]\n>>> avg_losses = [compute_average_loss(res_dict, k) for k in k_factors]\n>>> assert np.isclose(compute_average_loss(res_dict, 10), 0.5333333333333333)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> res_dict = {'TP_count': 100, 'FP_count': 20, 'TN_count': 450, 'FN_count': 30}\n>>> k_factors = [0, 10, 100]\n>>> avg_losses = [compute_average_loss(res_dict, k) for k in k_factors]\n>>> assert np.isclose(compute_average_loss(res_dict, 100), 5.033333333333333)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> alpha_values = [0.05, 0.1, 0.2, 0.4]\n>>> k_factors = [0, 10, 100]\n>>> inputs = list(itertools.product(alpha_values, k_factors))\n>>> outputs = [compute_alpha_average_loss(p_values, reality, *inp) for inp in inputs]\n>>> answers = [0.0472, 0.7432, 7.0072, 0.0965, 0.6805, 5.9365, 0.1863, 0.6143, 4.4663, 0.3692, 0.5942, 2.6192]\n>>> assert np.allclose(outputs, answers)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> prevalences = [0.001, 0.01, 0.1]\n>>> sensitivities = [1, 0.95, 0.9, 0.8]\n>>> specificities = [1, 0.99, 0.95, 0.9]\n>>> inputs = list(itertools.product(prevalences, sensitivities, specificities))\n>>> outputs = [compute_posterior_probability(*inp) for inp in inputs]\n>>> test_cases = [1.0, 0.091, 0.02, 0.01, 1.0, 0.087, 0.019, 0.009, 1.0, 0.083, 0.018, 0.009, 1.0, 0.074, 0.016, 0.008, 1.0, 0.503, 0.168, 0.092, 1.0, 0.49, 0.161, 0.088, 1.0, 0.476, 0.154, 0.083, 1.0, 0.447, 0.139, 0.075, 1.0, 0.917, 0.69, 0.526, 1.0, 0.913, 0.679, 0.514, 1.0, 0.909, 0.667, 0.5, 1.0, 0.899, 0.64, 0.471]\n>>> assert np.allclose(outputs, test_cases)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> treatments = [0, 1]\n>>> k_factors = [0, 10, 100]\n>>> posterior_probabilities = [0.1, 0.5, 0.9]\n>>> inputs = list(itertools.product(treatments, posterior_probabilities, k_factors))\n>>> outputs = [compute_expected_loss(*inp) for i, inp in enumerate(inputs)]\n>>> test_cases = [0.0, 1.0, 10.0, 0.0, 5.0, 50.0, 0.0, 9.0, 90.0, 0.9, 0.9, 0.9, 0.5, 0.5, 0.5, 0.1, 0.1, 0.1]\n>>> assert np.allclose(outputs, test_cases)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2d": {
     "name": "q2d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> k_factors = [0, 10, 100]\n>>> posterior_probabilities = [0.1, 0.5, 0.9]\n>>> inputs = list(itertools.product(posterior_probabilities, k_factors))\n>>> outputs = [make_decision(*inp) for i, inp in enumerate(inputs)]\n>>> test_cases = [0, 1, 1, 0, 1, 1, 0, 1, 1]\n>>> assert np.allclose(outputs, test_cases)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
